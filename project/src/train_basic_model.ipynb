{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf57651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from  matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ee6d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5080b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_path = './data/widerface/train/images/'\n",
    "label_txt = os_path[:-7] + 'label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16de5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_path = './data/widerface/train/images/'\n",
    "def get_list_from_filenames(file_path):\n",
    "    images_paths =[]\n",
    "    labels,key = [], \"\"\n",
    "    with open(label_txt, 'r') as fr:\n",
    "        test_dataset = fr.read().split(\"\\n\")\n",
    "    for i, each_line in enumerate(test_dataset):\n",
    "        if(len(each_line)>0 and each_line[0] == '#'):\n",
    "            images_paths.append(each_line[2:])\n",
    "            key = each_line[2:]\n",
    "        else:\n",
    "            if each_line!='':\n",
    "                labels.append((key,np.array(each_line.split()).astype('float32'))) \n",
    "    return images_paths,labels\n",
    "images_paths,labels = get_list_from_filenames(os_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381de0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_params(model):\n",
    "    # Generator function that yields ignored params.\n",
    "    b = [model.conv1, model.bn1, model.fc_finetune]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_non_ignored_params(model):\n",
    "    # Generator function that yields params that will be optimized.\n",
    "    b = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_fc_params(model):\n",
    "    # Generator function that yields fc layer params.\n",
    "    b = [model.fc_yaw, model.fc_pitch, model.fc_roll]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def load_filtered_state_dict(model, snapshot):\n",
    "    # By user apaszke from discuss.pytorch.org\n",
    "    model_dict = model.state_dict()\n",
    "    snapshot = {k: v for k, v in snapshot.items() if k in model_dict}\n",
    "    model_dict.update(snapshot)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db1abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_bins):\n",
    "        self.inplanes = 64\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc_yaw = nn.Linear(512 * block.expansion, num_bins)\n",
    "        self.fc_pitch = nn.Linear(512 * block.expansion, num_bins)\n",
    "        self.fc_roll = nn.Linear(512 * block.expansion, num_bins)\n",
    "\n",
    "        self.fc_finetune = nn.Linear(512 * block.expansion + 3, 3)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        pre_yaw = self.fc_yaw(x)\n",
    "        pre_pitch = self.fc_pitch(x)\n",
    "        pre_roll = self.fc_roll(x)\n",
    "\n",
    "        return pre_yaw, pre_pitch, pre_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772783d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customised Image dataset to be used for dataloader\n",
    "class WiderDataset(Dataset):\n",
    "    def __init__(self,data_dir,transform,img_n_labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.X_y = img_n_labels\n",
    "        self.image_mode = 'G'\n",
    "        self.length = len(img_n_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    \n",
    "    # face_x face_y face_width face_height landmark1.x landmark1.y 0.0 \n",
    "    # landmark2.x landmark2.y 0.0 landmark3.x landmark3.y 0.0 landmark4.x \n",
    "    # landmark4.y 0.0landmark5.x landmark5.y 0.0 confidence pitch yaw roll\n",
    "    def __getitem__(self, idx):\n",
    "        if self.image_mode == 'G':\n",
    "            img = Image.open(self.data_dir + self.X_y[idx][0])\n",
    "        else:\n",
    "            img = Image.open(self.data_dir + self.X_y[idx][0])\n",
    "        label_info = self.X_y[idx][1]\n",
    "        \n",
    "        face_x, face_y, face_width, face_height = label_info[0], label_info[1], label_info[2], label_info[3]\n",
    "        \n",
    "        img = img.crop((int(face_x), int(face_y), int(face_x+face_width), int(face_y+face_height)))\n",
    "        imag_name = self.data_dir + self.X_y[idx][0]\n",
    "        #print(\"loading image:\",imag_name)\n",
    "        pitch = label_info[-3]\n",
    "        yaw = label_info[-2]\n",
    "        roll = label_info[-1]\n",
    "        \n",
    "        landmark1 = label_info[4:6]\n",
    "        landmark2 = label_info[7:9]\n",
    "        landmark3 = label_info[10:12]\n",
    "        landmark4 = label_info[13:15]\n",
    "        landmark5 = label_info[16:18]\n",
    "        # Bin values\n",
    "        bins = np.array(range(-99, 102, 3))\n",
    "        binned_pose = np.digitize([yaw, pitch, roll], bins) - 1\n",
    "        labels = binned_pose\n",
    "        cont_labels = torch.FloatTensor([yaw, pitch, roll])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,labels, cont_labels, self.X_y[idx][0]+str(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712916db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], 66)\n",
    "load_filtered_state_dict(model, model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b22c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Resize(240),\n",
    "    transforms.RandomCrop(224), transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40eab24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BharathBandaru/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "criterion = nn.CrossEntropyLoss().cpu()\n",
    "reg_criterion = nn.MSELoss().cpu()\n",
    "lr=0.001\n",
    "alpha = 0.001\n",
    "num_epochs = 1\n",
    "softmax = nn.Softmax(dim=1).cpu()\n",
    "idx_tensor = [idx for idx in range(66)]\n",
    "idx_tensor = Variable(torch.FloatTensor(idx_tensor)).cpu()\n",
    "optimizer = torch.optim.Adam([{'params': get_ignored_params(model), 'lr': 0},\n",
    "                                  {'params': get_non_ignored_params(model), 'lr': lr},\n",
    "                                  {'params': get_fc_params(model), 'lr': lr * 5}],\n",
    "                                   lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f646a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 31437\n",
      "Test size: 25150\n",
      "Validation size: 100600\n"
     ]
    }
   ],
   "source": [
    "train_labels, valid_labels = train_test_split(labels, test_size=0.8)\n",
    "valid_labels, test_labels = train_test_split(valid_labels, test_size=0.8)\n",
    "print(\"Train size: {}\".format(len(train_labels)))\n",
    "print(\"Test size: {}\".format(len(valid_labels)))\n",
    "print(\"Validation size: {}\".format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77809a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=WiderDataset(os_path,transformations,train_labels)\n",
    "validation_dataset=WiderDataset(os_path,transformations,valid_labels)\n",
    "test_dataset=WiderDataset(os_path,transformations,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89160154",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=100\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=validation_dataset,\n",
    "                                               batch_size=batch,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ab50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/BharathBandaru/opt/anaconda3/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/BharathBandaru/opt/anaconda3/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'WiderDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels, cont_labels, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      3\u001b[0m         images \u001b[38;5;241m=\u001b[39m Variable(images)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Binned labels\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:352\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:294\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _SingleProcessDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:801\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    794\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels, cont_labels, name) in enumerate(train_loader):\n",
    "        images = Variable(images).cpu()\n",
    "\n",
    "        # Binned labels\n",
    "        label_yaw = Variable(labels[:,0]).cpu()\n",
    "        label_pitch = Variable(labels[:,1]).cpu()\n",
    "        label_roll = Variable(labels[:,2]).cpu()\n",
    "\n",
    "        # Continuous labels\n",
    "        label_yaw_cont = Variable(cont_labels[:,0]).cpu()\n",
    "        label_pitch_cont = Variable(cont_labels[:,1]).cpu()\n",
    "        label_roll_cont = Variable(cont_labels[:,2]).cpu()\n",
    "\n",
    "        # Forward pass\n",
    "        yaw, pitch, roll = model(images)\n",
    "\n",
    "        # Cross entropy loss\n",
    "        loss_yaw = criterion(yaw, label_yaw)\n",
    "        loss_pitch = criterion(pitch, label_pitch)\n",
    "        loss_roll = criterion(roll, label_roll)\n",
    "\n",
    "        # MSE loss\n",
    "        yaw_predicted = softmax(yaw)\n",
    "        pitch_predicted = softmax(pitch)\n",
    "        roll_predicted = softmax(roll)\n",
    "\n",
    "        yaw_predicted = torch.sum(yaw_predicted * idx_tensor, 1) * 3 - 99\n",
    "        pitch_predicted = torch.sum(pitch_predicted * idx_tensor, 1) * 3 - 99\n",
    "        roll_predicted = torch.sum(roll_predicted * idx_tensor, 1) * 3 - 99\n",
    "\n",
    "        loss_reg_yaw = reg_criterion(yaw_predicted, label_yaw_cont)\n",
    "        loss_reg_pitch = reg_criterion(pitch_predicted, label_pitch_cont)\n",
    "        loss_reg_roll = reg_criterion(roll_predicted, label_roll_cont)\n",
    "\n",
    "        # Total loss\n",
    "        loss_yaw += alpha * loss_reg_yaw\n",
    "        loss_pitch += alpha * loss_reg_pitch\n",
    "        loss_roll += alpha * loss_reg_roll\n",
    "\n",
    "        loss_seq = [loss_yaw, loss_pitch, loss_roll]\n",
    "        grad_seq = [torch.ones(1)[0].cpu() for _ in range(len(loss_seq))]\n",
    "        optimizer.zero_grad()\n",
    "        torch.autograd.backward(loss_seq, grad_seq)\n",
    "        optimizer.step()\n",
    "\n",
    "        print ('Epoch [%d/%d], Iter [%d/%d] Losses: Yaw %.4f, Pitch %.4f, Roll %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//100, loss_yaw.data, loss_pitch.data, loss_roll.data))\n",
    "\n",
    "    # Save models at numbered epochs.\n",
    "    if epoch % 1 == 0 and epoch < num_epochs:\n",
    "        print('Taking snapshot...')\n",
    "        torch.save(model.state_dict(),\n",
    "        'output/snapshots/' + \"temp\" + '_epoch_'+ str(epoch+1) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d450b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
