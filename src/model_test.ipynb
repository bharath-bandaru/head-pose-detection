{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujHi9xeLTgbt",
    "outputId": "ad874a0e-71e3-4f44-dd00-6dbb4a148d80"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math   \n",
    "import os\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "from numpy.core.fromnumeric import argmax\n",
    "from facenet_pytorch import MTCNN, extract_face\n",
    "import cv2\n",
    "from  matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-f3ytNiSUDpE"
   },
   "outputs": [],
   "source": [
    "path ={\n",
    "    # download training data from drive\n",
    "    \"train\" : '../data/train/AFW',\n",
    "    \"model1\" : '../data/models/model1.h5',\n",
    "    \"model2\" : '../data/models/resnet.h5',\n",
    "    \"model3\" : '../data/models/cross-entropy.h5',\n",
    "    \"test\" : '../data/images/test_3.png',\n",
    "    \"test_group\": '../data/images/group_3.png'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NmGoHmvWToVi"
   },
   "outputs": [],
   "source": [
    "idx_tensor = [idx for idx in range(66)]\n",
    "idx_tensor = tf.Variable(np.array(idx_tensor, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RkHJjqWKTyok"
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "def loss_function(y_true, y_pred):\n",
    "  real_true = y_true[:,0]\n",
    "  bin_true = y_true[:,1]\n",
    "  cat_f = tf.keras.losses.CategoricalCrossentropy(\n",
    "  from_logits=True)\n",
    "  bin_one_hot = tf.keras.utils.to_categorical(bin_true.numpy(),66)\n",
    "  cls_loss = cat_f(bin_one_hot, y_pred)\n",
    "  # # MSE loss\n",
    "  pred_cont = tf.reduce_sum(tf.nn.softmax(y_pred) * idx_tensor, 1) * 3 - 99\n",
    "  mse_loss = tf.losses.mean_squared_error(real_true, pred_cont)\n",
    "  # # Total loss\n",
    "  total_loss = cls_loss + alpha * mse_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wK8nc7dRT0NA"
   },
   "outputs": [],
   "source": [
    "loaded_model = model = keras.models.load_model(path['model1'],custom_objects={\"loss_func\": loss_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IzigjWOAUesk"
   },
   "outputs": [],
   "source": [
    "from math import cos, sin\n",
    "def draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size = 100):\n",
    "\n",
    "    pitch = pitch * np.pi / 180\n",
    "    yaw = -(yaw * np.pi / 180)\n",
    "    roll = roll * np.pi / 180\n",
    "\n",
    "    if tdx != None and tdy != None:\n",
    "        tdx = tdx\n",
    "        tdy = tdy\n",
    "    else:\n",
    "        height, width = img.shape[:2]\n",
    "        tdx = width / 2\n",
    "        tdy = height / 2\n",
    "    x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "    x3 = size * (sin(yaw)) + tdx\n",
    "    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "Dpwm78NIQVXh",
    "outputId": "53cf7377-3b80-4c94-e336-4c03c557175d"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     21\u001b[0m test_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_group\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, img)\u001b[0m\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m (box[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mbox[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     17\u001b[0m     y \u001b[38;5;241m=\u001b[39m (box[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mbox[\u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     final_img \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopen_cv_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_cont_yaw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_cont_pitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_cont_roll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtdx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtdy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     img \u001b[38;5;241m=\u001b[39m final_img\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mdraw_axis\u001b[0;34m(img, yaw, pitch, roll, tdx, tdy, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_axis\u001b[39m(img, yaw, pitch, roll, tdx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tdy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     pitch \u001b[38;5;241m=\u001b[39m \u001b[43mpitch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m      5\u001b[0m     yaw \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(yaw \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m180\u001b[39m)\n\u001b[1;32m      6\u001b[0m     roll \u001b[38;5;241m=\u001b[39m roll \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m180\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "def test_model(model,img):\n",
    "    mtcnn = MTCNN(keep_all=True, post_process=False,min_face_size = 10)\n",
    "    boxes, probs, points = mtcnn.detect(img, landmarks=True)\n",
    "    for i, box in enumerate(boxes):\n",
    "        crop_img = extract_face(img, box, margin=50)\n",
    "        crop_img = np.transpose(crop_img,(1,2,0))\n",
    "        crop_img = crop_img.numpy()\n",
    "        crop_img = np.array(Image.fromarray(np.uint8(crop_img)))\n",
    "        crop_img = cv2.resize(crop_img,(240,240))\n",
    "        val =model.predict(np.array([crop_img]))\n",
    "        predictions = np.asarray(val)\n",
    "        pred_cont_yaw = tf.reduce_sum(tf.nn.softmax(predictions[0,:,:]) * idx_tensor, 1) * 3 - 99\n",
    "        pred_cont_pitch = tf.reduce_sum(tf.nn.softmax(predictions[1,:,:]) * idx_tensor, 1) * 3 - 99\n",
    "        pred_cont_roll = tf.reduce_sum(tf.nn.softmax(predictions[2,:,:]) * idx_tensor, 1) * 3 - 99\n",
    "        open_cv_image = np.array(Image.fromarray(np.uint8(img)))\n",
    "        x = (box[0]+box[2])/2\n",
    "        y = (box[1]+box[3])/2\n",
    "        final_img = draw_axis(open_cv_image, pred_cont_yaw[0], pred_cont_pitch[0], pred_cont_roll[0],tdx = x,tdy=y)\n",
    "        img = final_img\n",
    "    cv2_imshow(img)\n",
    "test_img = cv2.imread(path['test_group'])\n",
    "test_model(loaded_model,test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/images/test_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         ax\u001b[38;5;241m.\u001b[39mset_yticks([])\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# plot filter channel in grayscale\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mfeature_maps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mix\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m         ix \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# show the figure\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAApCAYAAACV8mGQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAlElEQVR4nO3ZsQ3DMAwFUTLwCEod7j+LNERqewdmAasgHCc44b+WKniAKskz01bz+PcCd1AUhaIolozaKodbaxkRN61SM8Y4MvN5NitFRYT13r+z1UXu/p7Nlrx+iqJQFIWiKBRFoSgKRVEoikJRFIqiUBSFV3493H03s+krzo+9Zk9kpSiKJa+foigURaEoCkVRfAC3thnzbS37LQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('../data/images/test_3.png')\n",
    "img = cv2.resize(img,(240,240))\n",
    "img = np.asarray([img])\n",
    "feature_maps = loaded_model.predict(img)\n",
    "# plot all 64 maps in an 8x8 squares\n",
    "square = 8\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = plt.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
